"""
FastAPI endpoints for CV embedding storage and vector similarity search.

These endpoints integrate with colleague's embedding generation script
and provide vector search capabilities using pgvector.
"""

import uuid
from typing import List, Optional
from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.orm import Session
import numpy as np

from ..database import get_db
from ..services.embedding_service import EmbeddingService, embedding_from_colleague_output
from ..services.csv_embedding_processor import CSVEmbeddingProcessor, process_colleague_csv
from ..models.embedding import Embedding
from ..models.document import Document
from ..schemas.parsed_document import ParsedDocument


router = APIRouter(prefix="/api/embeddings", tags=["embeddings"])


# Pydantic schemas for API requests/responses

from pydantic import BaseModel, Field
from typing import Any, Dict


class EmbeddingCreateRequest(BaseModel):
    """Request to store a new CV embedding."""
    document_id: uuid.UUID = Field(..., description="ID of the parsed document")
    embedding: List[float] = Field(..., description="Embedding vector (384, 768, or 1536 dimensions)")
    model_name: str = Field(default="sentence-transformers/all-MiniLM-L12-v2", description="Name of embedding model")
    overwrite: bool = Field(default=True, description="Overwrite existing embedding")


class ColleagueScriptOutput(BaseModel):
    """Expected output format from colleague's embedding script."""
    document_id: str = Field(..., description="Document UUID as string")
    embedding: List[float] = Field(..., description="Generated embedding vector")
    model_name: str = Field(default="colleague-script-v1.0", description="Model identifier")
    metadata: Optional[Dict[str, Any]] = Field(default=None, description="Additional metadata")


class CSVProcessRequest(BaseModel):
    """Request to process a CSV file with embeddings."""
    csv_file_path: str = Field(..., description="Path to CSV file (relative to backend/data/)")
    skip_existing: bool = Field(default=True, description="Skip embeddings that already exist")
    validate_documents: bool = Field(default=True, description="Validate document_id exists in DB")
    batch_size: int = Field(default=100, ge=1, le=1000, description="Batch size for processing")


class DirectoryProcessRequest(BaseModel):
    """Request to process all CSV files in a directory."""
    directory_path: str = Field(..., description="Path to directory (relative to backend/data/)")
    file_pattern: str = Field(default="*.csv", description="File pattern to match")
    skip_processed: bool = Field(default=True, description="Skip previously processed files")


class SimilaritySearchRequest(BaseModel):
    """Request for similarity search."""
    query_vector: List[float] = Field(..., description="Query embedding vector")
    limit: int = Field(default=10, ge=1, le=100, description="Max number of results")
    similarity_threshold: float = Field(default=0.7, ge=0.0, le=1.0, description="Minimum cosine similarity")
    exclude_document_ids: Optional[List[uuid.UUID]] = Field(default=None, description="Documents to exclude")


class JobMatchRequest(BaseModel):
    """Request for job-CV matching."""
    job_description_embedding: List[float] = Field(..., description="Job description embedding")
    skills_filter: Optional[List[str]] = Field(default=None, description="Required skills filter")
    experience_years_min: Optional[int] = Field(default=None, ge=0, description="Minimum years experience")
    limit: int = Field(default=20, ge=1, le=100, description="Max results")


class EmbeddingResponse(BaseModel):
    """Response with embedding details."""
    id: uuid.UUID
    document_id: uuid.UUID
    model_name: str
    model_dim: int
    is_active: bool
    created_at: str


class SimilarityResult(BaseModel):
    """Single similarity search result."""
    document_id: uuid.UUID
    similarity_score: float
    document_summary: Optional[Dict[str, Any]] = None  # Basic document info


class SimilaritySearchResponse(BaseModel):
    """Response for similarity search."""
    results: List[SimilarityResult]
    total_found: int
    query_info: Dict[str, Any]


# API Endpoints

@router.post("/store", response_model=EmbeddingResponse)
async def store_embedding(
    request: EmbeddingCreateRequest,
    session: Session = Depends(get_db)
):
    """
    Store a CV embedding vector in PostgreSQL with pgvector.
    
    Use this endpoint to store embeddings generated by your colleague's script.
    """
    try:
        service = EmbeddingService(session)
        
        embedding_record = await service.store_cv_embedding(
            document_id=request.document_id,
            embedding_vector=request.embedding,
            model_name=request.model_name,
            overwrite=request.overwrite
        )
        
        return EmbeddingResponse(
            id=embedding_record.id,
            document_id=embedding_record.document_id,
            model_name=embedding_record.model_name,
            model_dim=embedding_record.model_dim,
            is_active=embedding_record.is_active,
            created_at=embedding_record.created_at.isoformat()
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to store embedding: {str(e)}")


@router.post("/store-from-colleague-script", response_model=EmbeddingResponse)
async def store_from_colleague_script(
    script_output: ColleagueScriptOutput,
    session: Session = Depends(get_db)
):
    """
    Store embedding directly from colleague's script output format.
    
    This endpoint is designed to match the exact output format of your 
    colleague's embedding generation script for easy integration.
    """
    try:
        service = EmbeddingService(session)
        
        embedding_record = await service.store_cv_embedding(
            document_id=uuid.UUID(script_output.document_id),
            embedding_vector=script_output.embedding,
            model_name=script_output.model_name
        )
        
        return EmbeddingResponse(
            id=embedding_record.id,
            document_id=embedding_record.document_id,
            model_name=embedding_record.model_name,
            model_dim=embedding_record.model_dim,
            is_active=embedding_record.is_active,
            created_at=embedding_record.created_at.isoformat()
        )
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to store embedding: {str(e)}")


@router.post("/search/similar", response_model=SimilaritySearchResponse)
async def search_similar_cvs(
    request: SimilaritySearchRequest,
    session: Session = Depends(get_db)
):
    """
    Find CVs similar to a given embedding vector using cosine similarity.
    
    Returns CVs ordered by similarity score (1.0 = identical, 0.0 = orthogonal).
    """
    try:
        service = EmbeddingService(session)
        
        similar_cvs = await service.find_similar_cvs(
            query_vector=request.query_vector,
            limit=request.limit,
            similarity_threshold=request.similarity_threshold,
            exclude_document_ids=request.exclude_document_ids
        )
        
        results = []
        for document, similarity_score in similar_cvs:
            # Create basic document summary (avoid returning full parsed content)
            document_summary = {
                "id": str(document.id),
                "filename": getattr(document, "filename", None),
                "user_id": getattr(document, "user_id", None),
                "created_at": getattr(document, "created_at", None),
                # Add other safe fields as needed
            }
            
            results.append(SimilarityResult(
                document_id=document.id,
                similarity_score=round(similarity_score, 4),
                document_summary=document_summary
            ))
        
        return SimilaritySearchResponse(
            results=results,
            total_found=len(results),
            query_info={
                "vector_dimension": len(request.query_vector),
                "similarity_threshold": request.similarity_threshold,
                "excluded_documents": len(request.exclude_document_ids or [])
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Similarity search failed: {str(e)}")


@router.post("/search/job-match", response_model=SimilaritySearchResponse)  
async def search_job_matching_cvs(
    request: JobMatchRequest,
    session: Session = Depends(get_db)
):
    """
    Find CVs that match a job description embedding.
    
    This endpoint is optimized for matching candidates to job requirements
    using semantic similarity and optional filters.
    """
    try:
        service = EmbeddingService(session)
        
        matching_cvs = await service.search_by_job_description(
            job_description_embedding=request.job_description_embedding,
            skills_filter=request.skills_filter,
            experience_years_min=request.experience_years_min,
            limit=request.limit
        )
        
        results = []
        for document, similarity_score in matching_cvs:
            document_summary = {
                "id": str(document.id),
                "filename": getattr(document, "filename", None),
                "user_id": getattr(document, "user_id", None),
                # Add extracted key skills, experience years, etc. if available
                "preview": getattr(document, "parsed_content", "")[:200] + "..." if hasattr(document, "parsed_content") else None
            }
            
            results.append(SimilarityResult(
                document_id=document.id,
                similarity_score=round(similarity_score, 4),
                document_summary=document_summary
            ))
        
        return SimilaritySearchResponse(
            results=results,
            total_found=len(results),
            query_info={
                "vector_dimension": len(request.job_description_embedding),
                "skills_filter": request.skills_filter,
                "min_experience": request.experience_years_min
            }
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Job matching search failed: {str(e)}")


@router.get("/stats")
async def get_embedding_statistics(
    session: Session = Depends(get_db)
):
    """Get statistics about stored embeddings."""
    try:
        service = EmbeddingService(session)
        stats = await service.get_embedding_stats()
        return stats
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get stats: {str(e)}")


@router.get("/document/{document_id}/embedding")
async def get_document_embedding(
    document_id: uuid.UUID,
    session: Session = Depends(get_db)
):
    """Get the embedding for a specific document."""
    try:
        embedding = session.query(Embedding).filter(
            Embedding.document_id == document_id,
            Embedding.is_active == True
        ).first()
        
        if not embedding:
            raise HTTPException(status_code=404, detail="Embedding not found for this document")
        
        return {
            "id": embedding.id,
            "document_id": embedding.document_id,
            "embedding": embedding.embedding,  # Return the actual vector if needed
            "model_name": embedding.model_name,
            "model_dim": embedding.model_dim,
            "created_at": embedding.created_at.isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to retrieve embedding: {str(e)}")


@router.delete("/document/{document_id}/embedding")
async def delete_document_embedding(
    document_id: uuid.UUID,
    session: Session = Depends(get_db)
):
    """Soft delete (deactivate) an embedding for a document."""
    try:
        embedding = session.query(Embedding).filter(
            Embedding.document_id == document_id,
            Embedding.is_active == True
        ).first()
        
        if not embedding:
            raise HTTPException(status_code=404, detail="Active embedding not found for this document")
        
        embedding.is_active = False
        session.commit()
        
        return {"message": f"Embedding for document {document_id} deactivated successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        session.rollback()
        raise HTTPException(status_code=500, detail=f"Failed to delete embedding: {str(e)}")


# CSV Processing endpoints for colleague's workflow

@router.post("/process-csv")
async def process_csv_file(
    request: CSVProcessRequest,
    session: Session = Depends(get_db)
):
    """
    Process a CSV file generated by colleague's embedding script.
    
    Expected CSV format:
    document_id,embedding,model_name,vector_dim
    uuid-123,"[0.1,0.2,0.3,...]",sentence-transformers/all-MiniLM-L12-v2,384
    
    The CSV file should be placed in backend/data/ directory.
    """
    try:
        # Resolve file path relative to backend/data/
        import os
        base_dir = os.path.join(os.path.dirname(__file__), "..", "..", "data")
        full_csv_path = os.path.join(base_dir, request.csv_file_path)
        
        processor = CSVEmbeddingProcessor(session)
        results = processor.process_csv_file(
            csv_file_path=full_csv_path,
            skip_existing=request.skip_existing,
            validate_documents=request.validate_documents,
            batch_size=request.batch_size
        )
        
        return {
            "message": f"CSV processing complete",
            "file_path": request.csv_file_path,
            "results": results
        }
        
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"CSV file not found: {request.csv_file_path}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"CSV processing failed: {str(e)}")


@router.post("/process-directory")
async def process_csv_directory(
    request: DirectoryProcessRequest,
    session: Session = Depends(get_db)
):
    """
    Process all CSV files in a directory.
    
    Useful when colleague's script generates multiple CSV files.
    Directory path should be relative to backend/data/.
    """
    try:
        # Resolve directory path relative to backend/data/
        import os
        base_dir = os.path.join(os.path.dirname(__file__), "..", "..", "data")
        full_dir_path = os.path.join(base_dir, request.directory_path)
        
        processor = CSVEmbeddingProcessor(session)
        results = processor.process_directory(
            directory_path=full_dir_path,
            file_pattern=request.file_pattern,
            skip_processed=request.skip_processed
        )
        
        return {
            "message": f"Directory processing complete",
            "directory_path": request.directory_path,
            "results": results
        }
        
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"Directory not found: {request.directory_path}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Directory processing failed: {str(e)}")


@router.get("/processed-files")
async def get_processed_files_log():
    """Get list of previously processed CSV files."""
    try:
        processor = CSVEmbeddingProcessor()
        processed_files = processor.get_processed_files()
        
        return {
            "total_files_processed": len(processed_files),
            "processed_files": processed_files
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get processed files: {str(e)}")


# Batch operations for bulk data processing (kept for backward compatibility)

@router.post("/batch-store")
async def batch_store_embeddings(
    embeddings_data: List[ColleagueScriptOutput],
    batch_size: int = Query(default=100, ge=1, le=1000),
    session: Session = Depends(get_db)
):
    """
    Store multiple embeddings in batches for better performance.
    
    Useful when your colleague's script processes many CVs at once.
    """
    try:
        service = EmbeddingService(session)
        
        # Convert to the format expected by batch_store_embeddings
        batch_data = []
        for item in embeddings_data:
            batch_data.append({
                "document_id": uuid.UUID(item.document_id),
                "embedding": item.embedding,
                "model_name": item.model_name
            })
        
        created_embeddings = service.batch_store_embeddings(
            embeddings_data=batch_data,
            batch_size=batch_size
        )
        
        return {
            "message": f"Successfully stored {len(created_embeddings)} embeddings",
            "total_processed": len(embeddings_data),
            "batch_size": batch_size,
            "created_ids": [str(emb.id) for emb in created_embeddings[:10]]  # Show first 10
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Batch storage failed: {str(e)}")
