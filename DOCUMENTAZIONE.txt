PiazzaTi - Documentazione Progetto
================================

Descrizione
-----------
Web app full stack con backend FastAPI, frontend React e database PostgreSQL. Gestione CI/CD con GitHub Actions, Docker per sviluppo e produzione.

Struttura del progetto
----------------------
- backend/: API FastAPI, modelli, servizi, migrazioni (Alembic)
- frontend/: React/TypeScript, UI e chiamate API
- docker-compose.yml: orchestration del backend (database esterno per ora, non gestito da docker)
- .github/workflows/ci.yml: pipeline CI/CD (lint, test, build)

Setup rapido
------------
1. Clona il repository
   git clone https://github.com/MeryemeBanani/PiazzaTi.git
   cd PiazzaTi

2. Configurazione Database PostgreSQL locale (IMPORTANTE)
   - Assicurati di avere PostgreSQL installato e in esecuzione (pgAdmin lo cosniglio per avere un controllo visivo di ciò che succede al db)
   - Crea il database: psql -U postgres -c "CREATE DATABASE \"db_PiazzaTi\";" (per esempio, questo lo puoi fare su pgadmin senza scomodare la linea di comando)
   - Copia il file di configurazione: cp backend/.env.example backend/.env (ti serve per configurare il file .env che non ho caricato e anche voi non dovete caricare su git perchè contiene info sensibili)
   - Modifica backend/.env con le TUE credenziali:
     DB_USER=postgres
     DB_PASSWORD=la_tua_password
     DB_HOST=host.docker.internal  # per Docker, o localhost per sviluppo locale
     DB_PORT=5432
     DB_NAME=db_PiazzaTi
     DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

3. Backend
   Opzione A - Con Docker (consigliata):
     docker-compose up --build
   
   Opzione B - Sviluppo locale (non necessaria se volete solo testare)
     cd backend
     python -m venv venv
     .\venv\Scripts\activate
     pip install -r requirements.txt
     uvicorn app.main:app --reload

4. Test della connessione database (dovrebbe aprirvi una pagina web dove vedere i risultati delle query)
   - Backend: http://localhost:8000
   - Health check: http://localhost:8000/health
   - Test DB: http://localhost:8000/db-test (deve restituire "database_connected")

5. Migrazioni database (quando necessario)
   cd backend
   alembic upgrade head

6. Frontend (incompleto)
   cd frontend
   npm install
   npm start

Modifiche database effettuate:
--------
- PostgreSQL locale (non più in Docker per sviluppo)
- Nome database: db_PiazzaTi
- Configurazione tramite file .env (mai committare con credenziali!)
- Migrazioni con Alembic
- Tabelle principali: users, documents (JSONB), embeddings (pgvector), searches
- SQLAlchemy per ORM con connessione automatica da DATABASE_URL

Configurazione Database - Dettagli Tecnici
------------------------------------------
Il progetto usa SQLAlchemy per la connessione al database PostgreSQL:

1. File backend/app/database.py gestisce:
   - Caricamento automatico del DATABASE_URL da .env
   - Creazione del motore SQLAlchemy
   - SessionLocal per le transazioni
   - Base per i modelli ORM
   - Dependency get_db() per FastAPI

2. File backend/alembic/env.py configurato per:
   - Leggere DATABASE_URL da .env automaticamente
   - Gestire migrazioni su database locale

3. Endpoint di diagnostica:
   - /health: verifica configurazione
   - /db-test: testa connessione effettiva

4. Sicurezza:
   - File .env escluso da git (.gitignore)
   - Template .env.example per altri sviluppatori
   - Credenziali mai presenti nel codice, ad esempio la password di postgresql

Migrazioni Database MVP - Schema Aggiornato
------------------------------------------
Il progetto include una migrazione Alembic completa (001_mvp_update.py) che aggiorna 
lo schema database per l'MVP con ottimizzazioni strategiche:

DOCUMENTS - Aggiornamenti principali:
• Nuovi campi:
  - title: titolo leggibile per UI immediata
  - description_raw: testo originale per XAI e highlight skill
  - version: versioning CV (utente può caricare più versioni)
  - is_latest: flag per CV attivo (solo uno per utente)

• Vincoli di integrità:
  - language VARCHAR(2): standardizzazione ISO (evita "ITA/it/italiano")
  - status CHECK: solo valori validi (uploaded/parsed/failed)
  - UNIQUE parziale: un solo CV "latest" per utente

• Indici di performance:
  - GIN su parsed_json: query veloci su skill/requisiti
  - Parziale su JD aperti: ottimizza ricerche (status=parsed)
  - Unique latest CV: enforcement DB level

• View semplificate:
  - cv_documents: filtra solo CV
  - jd_documents: filtra solo Job Descriptions

EMBEDDINGS - Ottimizzazioni similarity search:
• FK CASCADE: cleanup automatico embedding orfani
• Indice ANN ivfflat: nearest-neighbor search veloce
  - lists=100: divide spazio vettoriale in 100 cluster
  - cosine ops: distanza coseno per embedding normalizzati
  - Performance: 10-100x più veloce delle scansioni lineari

SEARCHES - Audit e cronologia:
• Indice (user_id, created_at): cronologia ricerche veloce

SEARCH_RESULTS - Tracciamento completo:
• created_at DEFAULT NOW(): timestamp per audit e fairness
• clicked DEFAULT false: consistenza dati
• FK CASCADE: integrità relazionale
• Indice (search_id, rank): query top-k risultati ottimizzate

Comando per applicare le migrazioni:
   cd backend
   python -m alembic upgrade head

IMPORTANTE: Per sviluppo locale, usare DB_HOST=localhost nel .env
Per Docker, usare DB_HOST=host.docker.internal

Troubleshooting Database
-----------------------
- Errore "database non esiste": Creare db_PiazzaTi con psql
- Errore "connessione rifiutata": Verificare che PostgreSQL sia in esecuzione
- Errore "password errata": Controllare credenziali in .env
- Docker non si connette: Usare host.docker.internal invece di localhost

CI/CD
-----
- Lint e test automatici su ogni push/pull request (GitHub Actions)
- Build Docker automatica

Testing
-------
- Test Python in backend/tests/ con pytest
- Lint con flake8

Contributi
----------
1. Crea un branch da dev o feature
2. Configura il tuo .env locale (copia da .env.example)
3. Fai commit e push (il .env non verrà mai committato)
4. Apri una pull request
